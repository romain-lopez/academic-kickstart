%
% unpublished
%

@article {totalVIjournal,
	author = {Gayoso*, Adam and Steier*, Zo{\"e} and \myname{} and Regier, Jeffrey and Nazor, Kristopher L and Streets, Aaron and Yosef, Nir},
	title = {Joint Probabilistic Modeling of Paired Transcriptome and Proteome Measurements in Single Cells},
	journal = {Submitted},
	month={December},
    year = {2020},
    keywords = {insubmission},
    projects = "scVI",
    addendum={\href{https://www.biorxiv.org/content/10.1101/2020.05.08.083337v1}{\scriptsize [PDF]}},
    url_pdf={https://www.biorxiv.org/content/10.1101/2020.05.08.083337v1},
    url_code={https://github.com/YosefLab/scVI},
	abstract = {The paired measurement of RNA and surface protein abundance in single cells with CITE-seq is a promising approach to connect transcriptional variation with cell phenotypes and functions. However, each data modality exhibits unique technical biases, making it challenging to conduct a joint analysis and combine these two views into a unified representation of cell state. Here we present Total Variational Inference (totalVI), a framework for the joint probabilistic analysis of paired RNA and protein data from single cells. totalVI probabilistically represents the data as a composite of biological and technical factors such as limited sensitivity of the RNA data, background in the protein data, and batch effects. To evaluate totalVI, we performed CITE-seq on immune cells from murine spleen and lymph nodes with biological replicates and with different antibody panels measuring over 100 surface proteins. With this dataset we demonstrate that totalVI provides a cohesive solution for common analysis tasks like the integration of datasets with matched or unmatched protein panels, dimensionality reduction, clustering, evaluation of correlations between molecules, and differential expression testing. totalVI enables scalable, end-to-end analysis of paired RNA and protein data from single cells and is available as open-source software.},
}

@article{scanvi,
author = {Chenling Xu* and \myname{}* and Edouard Mehlman* and Jeffrey Regier and Michael I. Jordan and Nir Yosef},
journal = {Submitted},
title = {{Probabilistic Harmonization and Annotation of Single-cell Transcriptomics Data with Deep Generative Models}},
month={December},
year = {2020},
keywords = {insubmission},
projects="scVI",
addendum={\href{https://www.biorxiv.org/content/10.1101/532895v1}{\scriptsize [PDF]}},
    url_pdf={https://www.biorxiv.org/content/10.1101/532895v1},
    url_code={https://github.com/YosefLab/scVI},
abstract="As single-cell transcriptomics becomes a mainstream technology, the natural next step is to integrate the accumulating data in order to achieve a common ontology of cell types and states. However, owing to various nuisance factors of variation, it is not straightforward how to compare gene expression levels across data sets and how to automatically assign cell type labels in a new data set based on existing annotations. In this manuscript, we demonstrate that our previously developed method, scVI, provides an effective and fully probabilistic approach for joint representation and analysis of cohorts of single-cell RNA-seq data sets, while accounting for uncertainty caused by biological and measurement noise. We also introduce single-cell ANnotation using Variational Inference (scANVI), a semi-supervised variant of scVI designed to leverage any available cell state annotations --- for instance when only one data set in a cohort is annotated, or when only a few cells in a single data set can be labeled using marker genes. We demonstrate that scVI and scANVI compare favorably to the existing methods for data integration and cell state annotation in terms of accuracy, scalability, and adaptability to challenging settings such as a hierarchical structure of cell state labels. We further show that different from existing methods, scVI and scANVI represent the integrated datasets with a single generative model that can be directly used for any probabilistic decision making task, using differential expression as our case study. scVI and scANVI are available as open source software and can be readily used to facilitate cell state annotation and help ensure consistency and reproducibility across studies.",
}

@article{POXM,
  author    = {\myname{} and
               Inderjit Dhillon and
               Michael I. Jordan},
  title     = {{Learning from eXtreme Bandit Feedback}},
  journal   = {Submitted},
  month={December},
  year      = {2020},
  projects="counterfactuals",
  keywords = {insubmission},
  addendum={\href{https://arxiv.org/abs/2009.12947}{\scriptsize [PDF]}},
url_pdf = {https://arxiv.org/abs/2009.12947},
abstract="We study the problem of batch learning from bandit feedback in the setting of extremely large action spaces. Learning from extreme bandit feedback is ubiquitous in recommendation systems, in which billions of decisions are made over millions of choices in a single day, yielding massive observational data. In these large-scale real-world applications, supervised learning approaches such as eXtreme Multi-label Classification (XMC) remain the standard approach despite the bias inherent in the data collection process. Conversely, previously developed importance sampling approaches are unbiased but suffer from impractical variance when dealing with a large number of actions. 
In this paper, we introduce a selective importance sampling estimator (sIS) with more favorable bias-variance tradeoff. Specifically, sIS is obtained by performing importance sampling on the conditional expectation of the reward with respect to a small subset of actions for each instance (a form of Rao-Blackwellization). We employ this estimator in a novel algorithmic procedure---named Policy Optimization for eXtreme Models (POXM)---for learning from bandit feedback on XMC tasks. In POXM, the selected actions for the sIS estimator are the top-p actions of the logging policy, where p is adjusted from the data and is significantly smaller than the size of the action space. 
We use a supervised-to-bandit conversion on three XMC datasets to benchmark our POXM method against BanditNet, a previously applied partial matching pruning strategy as well as a supervised learning baseline. Whereas BanditNet sometimes improves marginally over the logging policy, our experiments show that POXM systematically and significantly improves over all baselines."
}

%
% 2020
%

@article{decision_making,
author = {\myname{} and Pierre Boyeau and Nir Yosef and Michael I. Jordan and Jeffrey Regier}, 
title = {Decision-Making with Auto-Encoding Variational Bayes},
projects = "science",
keywords = {conference, featured},
journal = {Advances in Neural Information Processing Systems},
year = {2020}, 
month = {November},
addendum={\href{https://www.arxiv.org/abs/2002.07217}{\scriptsize [PDF]}},
url_pdf = {https://www.arxiv.org/abs/2002.07217},
url_code= {https://github.com/PierreBoyeau/sbVAE},
abstract = {To make decisions based on a model fit by auto-encoding variational Bayes (AEVB), practitioners often let the variational distribution serve as a surrogate for the posterior distribution. This approach yields biased estimates of the expected risk, and therefore poor decisions for two reasons. First, the model fit by AEVB may yield biased statistics relative to the underlying data distribution. Second, there may be strong discrepancies between the variational distribution and the posterior. 
We explore how fitting the variational distribution based on several objective functions other than the ELBO, while continuing to fit the generative model based on the ELBO, affects the quality of downstream decisions.
For a particular model that is amenable to analysis, we investigate how importance sampling error as well as the biases in model parameter estimates vary across several approximate posteriors when used as proposal distributions.
Our theoretical results suggest that a posterior approximation distinct from the variational distribution should be used for making decisions. Motivated by these theoretical results, we propose learning several approximate proposals for the best model and combining them using multiple importance sampling for decision-making. In addition to toy examples, we present a full-fledged case study of single-cell RNA sequencing. In this challenging instance of multiple hypothesis testing, our proposed approach surpasses the current state of the art..}}

@article{review_paper,
author = {\myname{} and Adam Gayoso and Nir Yosef},
keywords = {review,featured},
journal = {Molecular Systems Biology},
title = {{Enhancing ScientiÔ¨Åc Discoveries in Molecular Biology with Deep Generative Models}},
addendum={\href{https://www.embopress.org/doi/epdf/10.15252/msb.20199198}{\scriptsize [PDF]}},
year = {2020},
month={July},
url_pdf={https://www.embopress.org/doi/epdf/10.15252/msb.20199198},
projects="science",
abstract = "Generative models provide a well established statistical framework for evaluating uncertainty and deriving conclusions from large data sets especially in the presence of  noise, sparsity and bias. Initially developed for computer vision and natural language processing, these models have been shown to effectively summarize the complexity that underlies many types of data and enable a range of applications including supervised analysis, such as assigning labels to images, unsupervised tasks such as dimensionality reduction, and extrapolation analysis such as de-novo generation of artificial images. With this early success, the power of generative models is now being increasingly leveraged in molecular biology, with applications ranging from designing new molecules with properties of interest, to identifying deleterious mutations in our genomes, and to making sense out of transcriptional variability between single cells. In this review, we provide a brief overview of the technical notions behind generative models and their implementation with deep learning techniques. We then describe several different ways in which these models can be utilized in practice, using several recent applications in molecular biology as examples.",
}

@article{CCPOvSIRE,
author = {\myname{} and Chenchen Li and Xiang Yan and Junwu Xiong and Michael I. Jordan and Yuan Qi and Le Song},
keywords = {conference},
journal = {AAAI Conference on Artificial Intelligence},
title = {{Cost-Effective Incentive Allocation via Structured Counterfactual Inference}},
projects="counterfactuals",
year = {2020},
month={March},
    url_pdf={https://arxiv.org/pdf/1902.02495.pdf},
addendum={\href{https://arxiv.org/pdf/1902.02495.pdf}{\scriptsize [PDF]}},
abstract="We address a practical problem ubiquitous in modern industry, in which a mediator tries to learn a policy for allocating strategic financial incentives for customers in a marketing campaign and observes only bandit feedback. In contrast to traditional policy optimization frameworks, we rely on a specific assumption for the reward structure and we incorporate budget constraints. We develop a new two-step method for solving this constrained counterfactual policy optimization problem. First, we cast the reward estimation problem as a domain adaptation problem with supplementary structure. Subsequently, the estimators are used for optimizing the policy with constraints. We establish theoretical error bounds for our estimation procedure and we empirically show that the approach leads to significant improvement on both synthetic and real datasets.",
}

%
% 2019
%

@article{lfc_change,
author = {Pierre Boyeau and \myname{} and Jeffrey Regier and Adam Gayoso and Michael I. Jordan and Nir Yosef},
keywords = {workshop},
journal = {Machine Learning in Computational Biology (MLCB)},
title = {{Deep Generative Models for Detecting Differential Expression in Single Cells}},
year = {2019},
month={October},
projects="scVI",
addendum={\href{https://www.biorxiv.org/content/10.1101/794289v1}{\scriptsize [PDF]}},
url_pdf = {https://www.biorxiv.org/content/10.1101/794289v1},
url_code = {https://github.com/PierreBoyeau/lfc_estimation},
abstract = "Detecting differentially expressed genes is important for characterizing subpopulations of cells. However, in scRNA-seq data, nuisance variation due to technical factors like sequencing depth and RNA capture efficiency obscures the underlying biological signal. First, we show that deep generative models, which combined Bayesian statistics and deep neural networks, better estimate the log-fold-change in gene expression levels between subpopulations of cells. Second, we use Bayesian decision theory to detect differentially expressed genes while controlling the false discovery rate. Our experiments on simulated and real datasets show that our approach out-performs state-of-the-art DE frameworks. Finally, we introduce a technique for improving the posterior approximation, and show that it also improves differential expression performance.",
}

@article{AutoZI,
author = {Oscar Clivio and \myname{} and Jeffrey Regier and Adam Gayoso and Michael I. Jordan and Nir Yosef},
keywords = {workshop},
journal = {Machine Learning in Computational Biology (MLCB), \spotlight{}},
title = {{Detecting Zero-Inflated Genes in Single-Cell Transcriptomics Data}},
year = {2019},
month={October},
projects="scVI",
addendum={\href{https://www.biorxiv.org/content/10.1101/794875v1}{\scriptsize [PDF]}},
url_pdf = {https://www.biorxiv.org/content/10.1101/794875v1},
url_code = {https://github.com/oscarclivio/AutoZI_reproducibility},
abstract = "In single-cell RNA sequencing data, biological processes or technical factors may induce an overabundance of zero measurements. Existing probabilistic approaches to interpreting these data either model all genes as zero-inflated, or none. But the overabundance of zeros might be gene-specific. Hence, we propose the AutoZI model, which, for each gene, places a spike-and-slab prior on a mixture assignment between a negative binomial (NB) component and a zero-inflated negative binomial (ZINB) component. We approximate the posterior distribution under this model using variational inference, and employ Bayesian decision theory to decide whether each gene is zero-inflated. On simulated data, AutoZI outperforms the alternatives. On negative control data, AutoZI retrieves predictions consistent to a previous study on ERCC spike-ins and recovers similar results on control RNAs. Applied to several datasets and instances of the 10x Chromium protocol, AutoZI allows both biological and technical interpretations of zero-inflation. Finally, AutoZI's decisions on mouse embyronic stem-cells suggest that zero-inflation might be due to transcriptional bursting.",
}

@article{totalVIMLCB,
author = {Adam Gayoso and \myname{} and Zo\"{e} Steier and Jeffrey Regier and Aaron Streets and Nir Yosef},
keywords = {workshop},
journal = {Machine Learning in Computational Biology (MLCB)},
title = {{A Joint Model of RNA Expression and Surface Protein Abundance in Single Cells}},
year = {2019},
month={October},
projects="scVI",
addendum={\href{https://www.biorxiv.org/content/10.1101/791947v1}{\scriptsize [PDF]}},
url_pdf={https://www.biorxiv.org/content/10.1101/791947v1},
url_code={https://github.com/adamgayoso/totalVI_reproducibility},
abstract = "Cellular indexing of transcriptomes and epitopes by sequencing (CITE-seq) combines unbiased single-cell transcriptome measurements with surface protein quantification comparable to flow cytometry, the gold standard for cell type identification. However, current analysis pipelines cannot address the two primary challenges of CITE-seq data: combining both modalities in a shared latent space that harnesses the power of the paired measurements, and handling the technical artifacts of the protein measurement, which is obscured by non-negligible background noise. Here we present Total Variational Inference (totalVI), a fully probabilistic end-to-end framework for normalizing and analyzing CITE-seq data, based on a hierarchical Bayesian model. In totalVI, the mRNA and protein measurements for each cell are generated from a low-dimensional latent random variable unique to that cell, representing its cellular state. totalVI uses deep neural networks to specify conditional distributions. By leveraging advances in stochastic variational inference, it scales easily to millions of cells. Explicit modeling of nuisance factors enables totalVI to produce denoised data in both domains, as well as a batch-corrected latent representation of cells for downstream analysis tasks.",
}

@article{gimVI,
  title={A Joint Model of Unpaired Data from scRNA-seq and Spatial Transcriptomics for Imputing Missing Gene Expression Measurements},
  author={\myname{}* and Nazaret*, Achille and Langevin*, Maxime and Samaran*, Jules and Regier*, Jeffrey and Jordan, Michael I and Yosef, Nir},
  journal={ICML Workshop in Computational Biology, \spotlight{}, \beststudentposteraward{}},
  year={2019},
month={June},
projects="scVI",
  keywords = {workshop},
  addendum={\href{https://arxiv.org/pdf/1905.02269.pdf}{\scriptsize [PDF]}},
    url_pdf={https://arxiv.org/pdf/1905.02269.pdf},
    url_code={https://github.com/ANazaret/gimvi-reproducibility},
  abstract="Spatial studies of transcriptome provide biologists with gene expression maps of heterogeneous and complex tissues. However, most experimental protocols for spatial transcriptomics suffer from the need to select beforehand a small fraction of genes to be quantified over the entire transcriptome. Standard single-cell RNA sequencing (scRNA-seq) is more prevalent, easier to implement and can in principle capture any gene but cannot recover the spatial location of the cells. In this manuscript, we focus on the problem of imputation of missing genes in spatial transcriptomic data based on (unpaired) standard scRNA-seq data from the same biological tissue. Building upon domain adaptation work, we propose gimVI, a deep generative model for the integration of spatial transcriptomic data and scRNA-seq data that can be used to impute missing genes. After describing our generative model and an inference procedure for it, we compare gimVI to alternative methods from computational biology or domain adaptation on real datasets and outperform Seurat Anchors, Liger and CORAL to impute held-out genes.",
}

@article{scrublet,
author = {Wolock, Samuel L. and \myname{} and Klein, Allon M.},
journal = {Cell Systems},
title = {{Scrublet: Computational Identification of Cell Doublets in Single-cell Transcriptomic Data}},
year = {2019},
month={April},
keywords = {journal},
addendum={\href{https://www.sciencedirect.com/science/article/abs/pii/S2405471218304745}{\scriptsize [PDF]}},
url_pdf={https://www.sciencedirect.com/science/article/abs/pii/S2405471218304745},
url_code={https://github.com/AllonKleinLab/scrublet},
abstract="Single-cell RNA-sequencing has become a widely used, powerful approach for studying cell populations. However, these methods often generate multiplet artifacts, where two or more cells receive the same barcode, resulting in a hybrid transcriptome. In most experiments, multiplets account for several percent of transcriptomes and can confound downstream data analysis. Here, we present Scrublet (Single-Cell Remover of Doublets), a framework for predicting the impact of multiplets in a given analysis and identifying problematic multiplets. Scrublet avoids the need for expert knowledge or cell clustering by simulating multiplets from the data and building a nearest neighbor classifier. To demonstrate the utility of this approach, we test Scrublet on several datasets that include independent knowledge of cell multiplets.",
}


%
% 2018
%

@ARTICLE{HCV_NIPS,
   author = {\myname{} and {Regier}, Jeffrey and {Jordan}, Michael I. and {Yosef}, Nir},
    title = "{Information Constraints on Auto-Encoding Variational Bayes}",
    projects="science",
  journal = {Advances in Neural Information Processing Systems},
     year = 2018,
month={November},
     keywords = {conference, featured},
     addendum={\href{https://papers.nips.cc/paper/7850-information-constraints-on-auto-encoding-variational-bayes.pdf}{\scriptsize [PDF]}},
    url_pdf={https://papers.nips.cc/paper/7850-information-constraints-on-auto-encoding-variational-bayes.pdf},
    url_code={https://github.com/romain-lopez/HCV},
    abstract="Parameterizing the approximate posterior of a generative model with neural networks has become a common theme in recent machine learning research. While providing appealing flexibility, this approach makes it difficult to impose or assess structural constraints such as conditional independence. We propose a framework for learning representations that relies on Auto-Encoding Variational Bayes and whose search space is constrained via kernel-based measures of independence. In particular, our method employs the d-variable Hilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between the latent representations and arbitrary nuisance factors. We show how to apply this method to a range of problems, including the problems of learning invariant representations and the learning of interpretable representations. We also present a full-fledged application to single-cell RNA sequencing (scRNA-seq). In this setting the biological signal is mixed in complex ways with sequencing errors and sampling effects. We show that our method out-performs the state-of-the-art in this domain.",
}

@article {scVI,
	author = {\myname{} and Regier, Jeffrey and Cole, Michael B. and Jordan, Michael I. and Yosef, Nir},
	title = {{Deep Generative Modeling for Single-cell Transcriptomics}},
	year = {2018},
month={December},
    journal = {{Nature} {Methods}},
    keywords = {journal, featured},
    projects = "scVI",
    addendum={\href{https://www.nature.com/articles/s41592-018-0229-2}{\scriptsize [PDF]}},
    url_pdf={https://www.nature.com/articles/s41592-018-0229-2},
    url_code={https://github.com/YosefLab/scVI},
    abstract="Single-cell transcriptome measurements can reveal unexplored biological diversity, but they suffer from technical noise and bias that must be modeled to account for the resulting uncertainty in downstream analyses. Here we introduce single-cell variational inference (scVI), a ready-to-use scalable framework for the probabilistic representation and analysis of gene expression in single cells (https://github.com/YosefLab/scVI). scVI uses stochastic optimization and deep neural networks to aggregate information across similar cells and genes and to approximate the distributions that underlie observed expression values, while accounting for batch effects and limited sensitivity. We used scVI for a range of fundamental analysis tasks including batch correction, visualization, clustering, and differential expression, and achieved high accuracy for each task.",
}

@article{noisy_labels,
author = {Maxime Langevin and Edouard Mehlman and Jeffrey Regier and \myname{} and Michael I. Jordan and Nir Yosef},
journal = {Bay Area Machine Learning Symposium, \oral{}},
title = {{A Deep Generative Model for Semi-Supervised Classification with Noisy Labels}},
year = {2018},
month={August},
keywords = {workshop},
addendum={\href{https://arxiv.org/pdf/1809.05957.pdf}{\scriptsize [PDF]}},
url_pdf={https://arxiv.org/pdf/1809.05957.pdf},
url_code={https://github.com/maxime1310/fuzzy_labeling_scRNA},
abstract="Class labels are often imperfectly observed, due to mistakes and to genuine ambiguity among classes. We propose a new semi-supervised deep generative model that explicitly models noisy labels, called the Mislabeled VAE (M-VAE). The M-VAE can perform better than existing deep generative models which do not account for label noise. Additionally, the derivation of M-VAE gives new theoretical insights into the popular M1+M2 semi-supervised model.",
}

%
% 2017
%

@article{scVIworkshop,
  author    = {\myname{} and
               Jeffrey Regier and
               Michael I. Jordan and
               Nir Yosef},
  title     = {{A Deep Generative Model for Gene Expression profiles from Single-cell
               RNA Sequencing with Application to Differential Expression}},
  journal   = {NeurIPS Machine Learning workshop in Computational Biology, \spotlight{} and Bay Area Machine Learning Symposium, \oral{}},
  year      = {2017},
month={December},
  keywords = {workshop},
    addendum={\href{https://arxiv.org/pdf/1709.02082.pdf}{\scriptsize [PDF]}},
url_pdf={https://arxiv.org/pdf/1709.02082.pdf},
url_code={https://github.com/YosefLab/scVI},
projects="scVI",
abstract="We propose a probabilistic model for interpreting gene expression levels that are observed through single-cell RNA sequencing. In the model, each cell has a low-dimensional latent representation. Additional latent variables account for technical effects that may erroneously set some observations of gene expression levels to zero. Conditional distributions are specified by neural networks, giving the proposed model enough flexibility to fit the data well. We use variational inference and stochastic optimization to approximate the posterior distribution. The inference procedure scales to over one million cells, whereas competing algorithms do not. Even for smaller datasets, for several tasks, the proposed procedure outperforms state-of-the-art methods like ZIFA and ZINB-WaVE. We also extend our framework to account for batch effects and other confounding factors, and propose a Bayesian hypothesis test for differential expression that outperforms DESeq2.",
}







